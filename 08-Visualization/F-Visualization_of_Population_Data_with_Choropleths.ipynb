{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Population and Unemployment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip3 install cython\n",
    "# !sudo pip3 install cartopy\n",
    "# !sudo pip3 install geoplot\n",
    "# !sudo pip3 install descartes\n",
    "# !sudo pip3 install pysal\n",
    "# !sudo pip3 install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo -H pip3 install -U pip cython cartopy geoplot descartes pysal geopandas pandas numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import requests # to connect to the Census API\n",
    "import ast # for parsing the Census API response\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import geoplot\n",
    "import geoplot.crs as gcrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the choropleths, we need the shapefiles for the areas. Below we use \n",
    "# shapefiles that come from the US Census data\n",
    "# \n",
    "# More files at https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html\n",
    "# \n",
    "# Check also http://geojson.xyz/ for more shapefiles\n",
    "#\n",
    "shapefiles_zipcodes = \"http://www2.census.gov/geo/tiger/GENZ2017/shp/cb_2017_us_zcta510_500k.zip\"\n",
    "shapefiles_counties = \"http://www2.census.gov/geo/tiger/GENZ2017/shp/cb_2017_us_county_500k.zip\"\n",
    "shapefiles_states   = \"http://www2.census.gov/geo/tiger/GENZ2017/shp/cb_2017_us_state_500k.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GeoDataframe for US States and plot a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_states = gpd.read_file(shapefiles_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non-continental states\n",
    "df_states = df_states[ df_states.NAME!='Alaska' ] \n",
    "df_states = df_states[ df_states.NAME!='Hawaii' ] \n",
    "df_states = df_states[ df_states.NAME!='Puerto Rico' ] \n",
    "df_states = df_states[ df_states.NAME!='Guam' ] \n",
    "df_states = df_states[ df_states.NAME!='Commonwealth of the Northern Mariana Islands' ] \n",
    "df_states = df_states[ df_states.NAME!='American Samoa' ] \n",
    "df_states = df_states[ df_states.NAME!='United States Virgin Islands' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be 49. The 48 continental, plus DC\n",
    "assert( len(df_states) == 49 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_states.plot(\n",
    "    figsize=(10,10), \n",
    "    linewidth=0.2, \n",
    "    color='white', \n",
    "    edgecolor='black'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load US Counties Datafame and plot a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties = gpd.read_file(shapefiles_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be 3233 counties looaded\n",
    "assert( len(df_counties) == 3233 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only counties in the lower 48 states + DC\n",
    "keep_county = df_counties.STATEFP.isin(df_states.STATEFP.values)\n",
    "df_counties = df_counties[ keep_county ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be 3108 counties remaining\n",
    "assert(len(df_counties) == 3108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counties.plot(\n",
    "    figsize=(15,15), \n",
    "    linewidth=0.2,  \n",
    "    color='white', \n",
    "    edgecolor='black'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Census Data\n",
    "\n",
    "You need to get an API Key from http://api.census.gov/data/key_signup.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Census:\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def get(self, fields, geo, year=2010, dataset='sf1'):\n",
    "        fields = [','.join(fields)]\n",
    "        template_url = 'https://api.census.gov/data/{year}/{dataset}?key={key}&get='\n",
    "        base_url = template_url.format(year=str(year), dataset=dataset, key=self.key)\n",
    "        query = fields\n",
    "        for item in geo:\n",
    "            query.append(item)\n",
    "        add_url = '&'.join(query)\n",
    "        url = base_url + add_url\n",
    "        response = requests.get(url)\n",
    "        return ast.literal_eval(response.text) \n",
    "\n",
    "api_key = '627d4107b57d4576f2120d2b87b59c7440e5d2af'\n",
    "census = Census(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a Choropleth with Population of US States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch state population data from US Census\n",
    "census_response = census.get(['P0010001'], ['for=state:*'])\n",
    "# Manipulate the result from the US Census API and convert the result to a dataframe\n",
    "df_state_population = pd.DataFrame(census_response[1:], columns = ['Population', 'STATEFP'])\n",
    "df_state_population['Population'] = pd.to_numeric(df_state_population['Population'])\n",
    "df_state_population['LogPopulation'] = np.log10(df_state_population['Population'])\n",
    "# df_state_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = df_state_population.LogPopulation.hist()\n",
    "# df_state_population.LogPopulation.plot.kde(secondary_y=True, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the df_states geodataframe with population information\n",
    "states_choropleth = pd.merge(df_states, df_state_population, on='STATEFP')\n",
    "\n",
    "states_choropleth.plot(\n",
    "    figsize=(25,25), \n",
    "    column='LogPopulation', \n",
    "    cmap='Blues',  # select color scheme from http://matplotlib.org/users/colormaps.html\n",
    "    linewidth=0.1, \n",
    "    edgecolor='black'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a Choropleth with Population of US Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the US Census API for the population of each county\n",
    "census_response = census.get(['P0010001'], ['in=state:*', 'for=county:*'])\n",
    "# Manipulate the API response and put the results in a dataframe\n",
    "df_county_population = pd.DataFrame(census_response[1:], columns = ['Population', 'STATEFP', 'COUNTYFP'])\n",
    "df_county_population['Population'] = pd.to_numeric(df_county_population['Population'])\n",
    "df_county_population['LogPopulation'] = np.log10(df_county_population['Population'])\n",
    "# df_county_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_county_population.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_county_population.LogPopulation.plot.kde()\n",
    "df_county_population.LogPopulation.hist(bins=40, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the GeoDataFrame df_counties with the population data\n",
    "counties_choropleth = pd.merge(df_counties, df_county_population, on=['STATEFP', 'COUNTYFP'])\n",
    "\n",
    "counties_choropleth.plot(\n",
    "    figsize=(15,15), \n",
    "    column='LogPopulation', \n",
    "    cmap='Blues', # http://matplotlib.org/users/colormaps.html\n",
    "    # scheme='Quantiles', # alternatives are 'Quantiles', Equal_Interval', and 'Fisher_Jenks'; Quantiles requires PySAL\n",
    "    linewidth=0.1, \n",
    "    edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the state borders (with darker, thicker lines) on top of the counties\n",
    "\n",
    "ax = counties_choropleth.plot(\n",
    "    figsize=(15,15), \n",
    "    column='LogPopulation', \n",
    "    cmap='Blues', # http://matplotlib.org/users/colormaps.html\n",
    "    # scheme='Quantiles', # alternatives are 'Quantiles', Equal_Interval', and 'Fisher_Jenks'; Quantiles requires PySAL\n",
    "    linewidth=0.1, \n",
    "    edgecolor='black')\n",
    "\n",
    "df_states.plot(\n",
    "    figsize=(15,15), \n",
    "    linewidth=1, # thicker line\n",
    "    facecolor='none', # no color for fill\n",
    "    edgecolor='#333366', # color for the state borders\n",
    "    ax = ax # plot it on top of the counties plot\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the projection to Orthographic\n",
    "geoplot.choropleth(\n",
    "    counties_choropleth,\n",
    "    hue='LogPopulation',\n",
    "    categorical=False, # LogPopulation is continuous not categorical\n",
    "    k=10, # split LogPopulation into 10 bins for coloring\n",
    "    scheme='equal_interval', # Each bin has equal range for LogPopulation\n",
    "    cmap='Blues', # try Spectral_r, Spectral, or others from https://matplotlib.org/tutorials/colors/colormaps.html\n",
    "    linewidth=0.3,\n",
    "    projection=gcrs.Orthographic(),\n",
    "    figsize=(15, 15)\n",
    ").gridlines() # plot gridlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add state borders in the geoplot choropleth plot\n",
    "\n",
    "ax = geoplot.polyplot(\n",
    "    states_choropleth, \n",
    "    projection=gcrs.Orthographic(),\n",
    "    figsize=(15, 15),\n",
    "    linewidth = 0.5,\n",
    "    zorder = 2\n",
    ")\n",
    "\n",
    "geoplot.choropleth(\n",
    "    counties_choropleth,\n",
    "    hue='LogPopulation',\n",
    "    categorical=False, # LogPopulation is continuous not categorical\n",
    "    k=10, # split LogPopulation into 40 bins for coloring\n",
    "    scheme='equal_interval', # Each bin has equal range for LogPopulation\n",
    "    cmap='Blues', # try Spectral_r, Spectral, or others from https://matplotlib.org/tutorials/colors/colormaps.html\n",
    "    linewidth=0.3,\n",
    "    projection=gcrs.Orthographic(),\n",
    "    figsize=(15, 15),\n",
    "    ax = ax,\n",
    "    zorder = 0\n",
    ").gridlines(zorder=1) # plot gridlines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Data\n",
    "\n",
    "https://www.bls.gov/lau/\n",
    "    \n",
    " * Labor force data by county, not seasonally adjusted, latest 14 months https://www.bls.gov/web/metro/laucntycur14.txt\n",
    " \n",
    " * Labor force data by county, 2017 annual averages https://www.bls.gov/lau/laucnty17.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bls.gov/web/metro/laucntycur14.txt\"\n",
    "udf = pd.read_csv(\n",
    "    url,\n",
    "    skiprows=6,  # skip the first six lines; \n",
    "    header=None,  # we will supply the headers ourselves\n",
    "    skipfooter=6,  # the last six lines are notes; skip them\n",
    "    engine='python',  # we need this to use the skipfooter option\n",
    "    delimiter=\"|\",  # use | as the column delimeter\n",
    "    # skipinitialspace=True,  # ignore the space characters after the delimeter |\n",
    "    # thousands=\",\",  # specify that numbers use , for thousand separator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.columns = [\"LAUS\", \"STATEFP\", \"COUNTYFP\", \"County_Name\", \"Period\", \n",
    "               \"Labor_Force\", \"Employed\", \"Unemployed\", \"Rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert STATEFP and COUNTYFP to strings and add leading zeros\n",
    "# to allow for merging later on with the geodataframes\n",
    "# Interestingly, the initial file contains the zeros, but Pandas recognizes\n",
    "# the entries as numbers and converts to integers, so we are forced to convert back\n",
    "udf.STATEFP = udf.STATEFP.apply(str).str.zfill(2)\n",
    "udf.COUNTYFP = udf.COUNTYFP.apply(str).str.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the thousands=\",\"  option in read_csv allows Pandas to understand the \n",
    "# data type of these columns properly. If we do not use the option, the \n",
    "# code below can convert the values into recognizable numbers to be used by to_numeric\n",
    "# \n",
    "# Need to replace the comma-separator in the numbers with an empty character\n",
    "# to allow for proper conversion\n",
    "#\n",
    "udf.Labor_Force = pd.to_numeric(udf.Labor_Force.str.replace(',',''))\n",
    "udf.Employed = pd.to_numeric(udf.Employed.str.replace(',',''))\n",
    "udf.Unemployed = pd.to_numeric(udf.Unemployed.str.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now want to convert the \"Period\" to datetime\n",
    "# Let's take a look at the unique values\n",
    "udf.Period.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting \"Period\" to a proper date\n",
    "# We will need to remove spaces \n",
    "# We will also need to remove the notes (p) and (y); we need to escape the parentheses\n",
    "udf.Period = udf.Period.str.replace(' ','')\n",
    "udf.Period = udf.Period.str.replace('\\(p\\)','')\n",
    "udf.Period = udf.Period.str.replace('\\(y\\)','')\n",
    "udf.Period.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.Period = pd.to_datetime(udf.Period, format='%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_average = udf.pivot_table(\n",
    "    index = ['STATEFP','COUNTYFP', 'County_Name'],\n",
    "    values = ['Rate','Labor_Force'],\n",
    "    aggfunc = 'mean'\n",
    ")\n",
    "\n",
    "unemployment_average = unemployment_average.reset_index()\n",
    "unemployment_average.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_average.Rate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# County with the highest unemployment rate\n",
    "unemployment_average [ unemployment_average.Rate == unemployment_average.Rate.max() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# County with the lowest unemployment rate\n",
    "unemployment_average [ unemployment_average.Rate == unemployment_average.Rate.min() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# County with the median unemployment rate\n",
    "unemployment_average [ unemployment_average.Rate == unemployment_average.Rate.median() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_average.Rate.hist(bins=100,range=(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_average.Rate.plot.kde(xlim=(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = unemployment_average.Rate.hist(bins=100,range=(0,20), density=True, alpha=0.5)\n",
    "ax = unemployment_average.Rate.plot.kde(xlim=(0,20), ax=ax, linewidth=3)\n",
    "ax.set_xlabel(\"Unemployment Rate (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the GeoDataFrame df_counties with the unemployment data\n",
    "# Note that this will drop the rates for counties in Alaska and Hawaii\n",
    "# as this is an inner join, and we have dropped from df_counties Alaska and Hawaii\n",
    "unemployment_choropleth = pd.merge(df_counties, unemployment_average, on=['STATEFP', 'COUNTYFP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_choropleth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with https://www.bls.gov/web/metro/twmcort.pdf\n",
    "\n",
    "ax = geoplot.polyplot(\n",
    "    states_choropleth, \n",
    "    projection=gcrs.Orthographic(),\n",
    "    figsize=(15, 15),\n",
    "    linewidth = 0.5,\n",
    "    zorder = 2\n",
    ")\n",
    "\n",
    "geoplot.choropleth(\n",
    "    unemployment_choropleth,\n",
    "    hue='Rate',\n",
    "    categorical=False, # Unemployment rate is continuous not categorical\n",
    "    k=10, # split Unemployment into 10 bins for coloring\n",
    "    scheme='quantiles', # Use quantiles for creating the bins\n",
    "    cmap='coolwarm', # We use a **divergent** colormap, to show places with higher than average and lower than average https://matplotlib.org/tutorials/colors/colormaps.html\n",
    "    linewidth=0.3,\n",
    "    projection=gcrs.Orthographic(),\n",
    "    figsize=(15, 15),\n",
    "    ax = ax,\n",
    "    zorder = 0,\n",
    "    legend = True,\n",
    "    legend_kwargs={'loc': 'lower right'}\n",
    ").gridlines(zorder=1) # plot gridlines on top of the counties (zorder=0), but behind state lines (zorder=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Saving quantiles as a separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_quantiles = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = pd.qcut(unemployment_choropleth.Rate, num_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the ranges for the quantiles\n",
    "quantiles.drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the labels=Fase to get a number (0,1,2,3...) instead of the range labels \n",
    "unemployment_choropleth[\"qRate\"] = pd.qcut(unemployment_choropleth.Rate, num_quantiles, labels=False)\n",
    "unemployment_choropleth[\"Rate_range\"] = pd.qcut(unemployment_choropleth.Rate, num_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_choropleth.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigating map visualization bias: Area vs Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, where we visualize unemployment rates per county, we introduce a bias: Areas with large area get more prominently displayed. We can try to mitigate this bias, by using cartograms, which scale each area based on a factor that we desire. \n",
    "\n",
    "* **County weight proportional to county area**: Scaling factor `constant` (the default).\n",
    "* **County weight equal across all counties**: Scaling factor proportional to `1/area`\n",
    "* **County weight proportional to county population**: Scaling factor proportional to `population/area`\n",
    "\n",
    "So, for example, if we want each country to have an area proportional to its **population** instead of its **area**, we may want to use Density (population divided by area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density = Population / Area\n",
    "unemployment_choropleth[\"Density\"] = unemployment_choropleth.Labor_Force / unemployment_choropleth.ALAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize density to have a minimum value of 1... \n",
    "# Alternatively, we can do it to have a max value of 1 by dividing with max\n",
    "unemployment_choropleth[\"Density\"] = unemployment_choropleth.Density / unemployment_choropleth.Density.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the log, as densities are roughly log-normally distributed (as is population)\n",
    "# We also normalize it by dividing with the max value (to make it 0...1 )\n",
    "# Finally we add a multiplicative factor of 2\n",
    "unemployment_choropleth[\"LogDensity\"] = 2*np.log10(unemployment_choropleth.Density)/np.log10(unemployment_choropleth.Density.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics on LogDensity values\n",
    "unemployment_choropleth.LogDensity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = unemployment_choropleth.LogDensity.hist(bins=50,range=(0,2), density=True, alpha=0.5)\n",
    "ax = unemployment_choropleth.LogDensity.plot.kde(xlim=(0,2), ax=ax, linewidth=3)\n",
    "ax.set_xlabel(\"County Population Density (log-scale)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_choropleth[ unemployment_choropleth.Density == unemployment_choropleth.Density.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_min = unemployment_choropleth.LogDensity.min()\n",
    "density_max = unemployment_choropleth.LogDensity.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoplot.cartogram(\n",
    "    unemployment_choropleth,\n",
    "    scale='LogDensity',\n",
    "    limits=(density_min,density_max),\n",
    "    trace=False,\n",
    "    projection=gcrs.Orthographic(),\n",
    "    scheme='quantiles',\n",
    "    hue='Rate',\n",
    "    k=10,\n",
    "    cmap='coolwarm',\n",
    "    figsize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of doing manipulations of the density column on the dataframe,\n",
    "# we can instead write a scaling function\n",
    "def log_scale(minval, maxval):\n",
    "    def scalar(val):\n",
    "        max_scaling = 2\n",
    "        min_scaling = 0.0\n",
    "        normed_log = np.log10(val) - np.log10(minval)\n",
    "        max_log = np.log10(maxval) - np.log10(minval)\n",
    "        factor = (max_scaling-min_scaling) * normed_log/max_log + min_scaling\n",
    "        return factor\n",
    "    return scalar\n",
    "\n",
    "geoplot.cartogram(\n",
    "    unemployment_choropleth,\n",
    "    scale='Density',\n",
    "    scale_func=log_scale,\n",
    "    trace=False,\n",
    "    projection=gcrs.Orthographic(),\n",
    "    scheme='quantiles',\n",
    "    hue='Rate',\n",
    "    k=10,\n",
    "    cmap='coolwarm',\n",
    "    figsize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
